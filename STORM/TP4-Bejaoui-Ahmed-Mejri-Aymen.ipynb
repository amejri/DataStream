{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4-NMF-Bejaoui Ahmed et Mejri Aymen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les imports nécéssaires pour le tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, \\\n",
    "CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FtoV(_vectorizer=TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000, stop_words='english'), _random_state=1):\n",
    "    vectorizer = _vectorizer\n",
    "    random_state = _random_state\n",
    "    # Fetch data and vectorize\n",
    "    print(\"Loading dataset...\")\n",
    "    dataset = fetch_20newsgroups(shuffle=True, random_state=random_state,\n",
    "                                 remove=('headers', 'footers', 'quotes'))\n",
    "    data_samples = dataset.data[:2000]        \n",
    "    t0 = time()\n",
    "    features = vectorizer.fit_transform(data_samples)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))\n",
    "    return features, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def  NMFModel (features, _vectorizerName='tf_idf', _random_state=1, \n",
    "             _beta_loss=None, _init='random', _W=None, _H=None, _K = None):\n",
    "    \n",
    "    n_samples = 2000\n",
    "    n_features = 1000\n",
    "    n_top_words = 20\n",
    "    n_components = 10 if _K is None else _K\n",
    "    vectorizerName = _vectorizerName\n",
    "    random_state = _random_state\n",
    "    solver = 'cd' if _beta_loss is None else 'mu'\n",
    "    beta_loss = 'frobenius' if _beta_loss is None else _beta_loss\n",
    "    init = _init\n",
    "    print(\"Fitting the NMF model (\"+beta_loss+\" norm) with \"+str(vectorizerName)+\" features, \"\n",
    "       \"n_samples=%d and n_features=%d...\" % (n_samples, n_features))\n",
    "    \n",
    "    t0 = time()\n",
    "#     if _init is None:\n",
    "#         nmf = NMF(n_components=n_components, \n",
    "#                   random_state=_random_state,\n",
    "#                   solver = solver,\n",
    "#                   beta_loss = beta_loss,\n",
    "#                   alpha=.1, l1_ratio=.5).fit(features)\n",
    "#     else:\n",
    "    nmf = NMF(n_components=n_components, \n",
    "              random_state=_random_state,\n",
    "              solver = solver,\n",
    "              beta_loss = beta_loss,\n",
    "              alpha=.1, l1_ratio=.5)\n",
    "    nmf.fit_transform(features, W=_W, H=_H)\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "    print(\"\\nTopics in NMF model (\"+beta_loss+\" norm):\")\n",
    "    return nmf, n_top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runs(_vectorizer=None, _vectorizerName=None, _random_state=None, _beta_loss=None, \n",
    "               _init='random', _W=None, _H=None, _K=None,dprint=True):\n",
    "    features, feature_names = FtoV()\n",
    "    nmf, n_top_words = NMFModel(features, _vectorizerName, _random_state, _beta_loss, _init, _W, _H, _K)\n",
    "    print('nombre d\\'itération pour la convergence : ',str(nmf.n_iter_))\n",
    "    print(\"error : \",nmf.reconstruction_err_,' \\n')\n",
    "    if(dprint):\n",
    "        print_top_words(nmf, feature_names, n_top_words)\n",
    "    print('#########################################################################')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 0.311s.\n",
      "Fitting the NMF model (frobenius norm) with None features, n_samples=2000 and n_features=1000...\n",
      "done in 0.230s.\n",
      "\n",
      "Topics in NMF model (frobenius norm):\n",
      "nombre d'itération pour la convergence :  134\n",
      "error :  42.1386080031  \n",
      "\n",
      "Topic #0: just people don think like know time good make way really say right ve want did ll new use years\n",
      "Topic #1: windows use dos using window program os drivers application help software pc running ms screen files version card code work\n",
      "Topic #2: god jesus bible faith christian christ christians does heaven sin believe lord life church mary atheism belief human love religion\n",
      "Topic #3: thanks know does mail advance hi info interested email anybody looking card help like appreciated information send list video need\n",
      "Topic #4: car cars tires miles 00 new engine insurance price condition oil power speed good 000 brake year models used bought\n",
      "Topic #5: edu soon com send university internet mit ftp mail cc pub article information hope program mac email home contact blood\n",
      "Topic #6: file problem files format win sound ftp pub read save site help image available create copy running memory self version\n",
      "Topic #7: game team games year win play season players nhl runs goal hockey toronto division flyers player defense leafs bad teams\n",
      "Topic #8: drive drives hard disk floppy software card mac computer power scsi controller apple mb 00 pc rom sale problem internal\n",
      "Topic #9: key chip clipper keys encryption government public use secure enforcement phone nsa communications law encrypted security clinton used legal standard\n",
      "\n",
      "#########################################################################\n",
      "Loading dataset...\n",
      "done in 0.381s.\n",
      "Fitting the NMF model (frobenius norm) with None features, n_samples=2000 and n_features=1000...\n",
      "done in 0.243s.\n",
      "\n",
      "Topics in NMF model (frobenius norm):\n",
      "nombre d'itération pour la convergence :  124\n",
      "error :  42.1386082787  \n",
      "\n",
      "Topic #0: just people don think like know time good make way really say right ve want did ll new use years\n",
      "Topic #1: windows use dos using window program os drivers application help software pc running ms screen files version card code work\n",
      "Topic #2: god jesus bible faith christian christ christians does heaven sin believe lord life church mary atheism belief human love religion\n",
      "Topic #3: thanks know does mail advance hi info interested email anybody looking card help like appreciated information send list video need\n",
      "Topic #4: car cars tires miles 00 new engine insurance price condition oil power speed good 000 brake year models used bought\n",
      "Topic #5: edu soon com send university internet mit ftp mail cc pub article information hope program mac email home contact blood\n",
      "Topic #6: file problem files format win sound ftp pub read save site help image available create copy running memory self version\n",
      "Topic #7: game team games year win play season players nhl runs goal hockey toronto division flyers player defense leafs bad teams\n",
      "Topic #8: drive drives hard disk floppy software card mac computer power scsi controller apple mb 00 pc rom sale problem internal\n",
      "Topic #9: key chip clipper keys encryption government public use secure enforcement phone nsa communications law encrypted security clinton used legal standard\n",
      "\n",
      "#########################################################################\n",
      "Loading dataset...\n",
      "done in 0.314s.\n",
      "Fitting the NMF model (frobenius norm) with None features, n_samples=2000 and n_features=1000...\n",
      "done in 0.230s.\n",
      "\n",
      "Topics in NMF model (frobenius norm):\n",
      "nombre d'itération pour la convergence :  128\n",
      "error :  42.1386080329  \n",
      "\n",
      "Topic #0: just people don think like know time good make way really say right ve want did ll new use years\n",
      "Topic #1: windows use dos using window program os drivers application help software pc running ms screen files version card code work\n",
      "Topic #2: god jesus bible faith christian christ christians does heaven sin believe lord life church mary atheism belief human love religion\n",
      "Topic #3: thanks know does mail advance hi info interested email anybody looking card help like appreciated information send list video need\n",
      "Topic #4: car cars tires miles 00 new engine insurance price condition oil power speed good 000 brake year models used bought\n",
      "Topic #5: edu soon com send university internet mit ftp mail cc pub article information hope program mac email home contact blood\n",
      "Topic #6: file problem files format win sound ftp pub read save site help image available create copy running memory self version\n",
      "Topic #7: game team games year win play season players nhl runs goal hockey toronto division flyers player defense leafs bad teams\n",
      "Topic #8: drive drives hard disk floppy software card mac computer power scsi controller apple mb 00 pc rom sale problem internal\n",
      "Topic #9: key chip clipper keys encryption government public use secure enforcement phone nsa communications law encrypted security clinton used legal standard\n",
      "\n",
      "#########################################################################\n"
     ]
    }
   ],
   "source": [
    "init=['nndsvda','nndsvdar','random']\n",
    "k=20\n",
    "for i in init:\n",
    "    runs(_random_state=k,_init=i)\n",
    "    k=k+20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**interprétation :**\n",
    "<br> nous avons essayé 3 configurations d'initialisation possibles pour le \"init\". la première c'est le nndsva qui permet de faire une double décomposition des valeurs singulières non-négatives sur les features tout en remplaçant les valeurs négatives en 0. Cette méthode converge avec le minimum d'iteration avec un taux d'erruer minimale. Les autres initialisation (nndsvar et random) convergent moin rapidement avec un pourcentage d'erreur qui est semblable au \"nndsvda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 0.371s.\n",
      "Fitting the NMF model (frobenius norm) with None features, n_samples=2000 and n_features=1000...\n",
      "done in 0.062s.\n",
      "\n",
      "Topics in NMF model (frobenius norm):\n",
      "nombre d'itération pour la convergence :  30\n",
      "error :  42.1877454643  \n",
      "\n",
      "Topic #0: just people don like think know good time make way really right say ve want did new ll government use\n",
      "Topic #1: windows use dos using window help card program software pc drivers os video application looking running version files screen ftp\n",
      "Topic #2: god jesus bible faith christian christ does christians heaven sin believe lord life church mary atheism belief human love religion\n",
      "Topic #3: thanks know mail does advance interested info hi email anybody list like send new address post appreciated reply looking information\n",
      "Topic #4: 00 sale 10 condition price card new offer car 250 asking 15 12 today 20 50 11 cd 25 30\n",
      "Topic #5: edu soon com university internet send mit cc ftp article information hope need email pub home mail blood mac cs\n",
      "Topic #6: file files problem format win sound pub read ftp save site create self running copy image windows available added space\n",
      "Topic #7: game team games year win play season players nhl runs goal hockey flyers division player defense leafs toronto bad won\n",
      "Topic #8: drive drives hard disk floppy mac software controller mb scsi rom computer apple internal problems problem format cable digital western\n",
      "Topic #9: key chip clipper keys encryption public use secure enforcement phone encrypted communications user clinton message nsa going standard doesn 80\n",
      "\n",
      "#########################################################################\n",
      "Loading dataset...\n",
      "done in 0.321s.\n",
      "Fitting the NMF model (kullback-leibler norm) with None features, n_samples=2000 and n_features=1000...\n",
      "done in 2.524s.\n",
      "\n",
      "Topics in NMF model (kullback-leibler norm):\n",
      "nombre d'itération pour la convergence :  70\n",
      "error :  214.053822852  \n",
      "\n",
      "Topic #0: people just time like right know say way things did make don think really let want said ve work thing\n",
      "Topic #1: windows using thanks help need work hi use software know looking pc mail used does running video available info card\n",
      "Topic #2: god does true read say question subject believe religion says point know jesus mean people life christian matter mind christians\n",
      "Topic #3: thanks know mail interested like want new send just edu list does email reply post thing wondering advance price posting\n",
      "Topic #4: new time year 10 sale old offer 15 16 20 30 good weeks power great times test model condition 11\n",
      "Topic #5: use government com used data number states information university phone control general talk provide security 1993 state source large research\n",
      "Topic #6: edu file try remember soon problem think program hope mike com wrong space little article library win include couldn mit\n",
      "Topic #7: year team world game play second games win ll does said season won news st case hear years series nhl\n",
      "Topic #8: think don drive people number hard going read make need pretty tell trying actually bit post try mac order apple\n",
      "Topic #9: just like good way use don sure want got doesn need really thought better wrong doing does speed stuff make\n",
      "\n",
      "#########################################################################\n"
     ]
    }
   ],
   "source": [
    "beta=['frobenius','kullback-leibler']\n",
    "k=20\n",
    "for i in beta:\n",
    "    runs(_random_state=k,_beta_loss=i)\n",
    "    k=k+20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interprétation :** <br>\n",
    "lorsque nous utilsons le \"Kullback-Lieber cost\", Le NMF devient moins performant qu'avec le \" $ l_{2} $ cost \". En fait, il lui faut 3 fois plus de temps pour converger et il tend à faire plus d'erreur.\n",
    "\n",
    "De plus, les topics trouvés avec les deux fonctions couts semblent être identiques(religion, programmation, jeux...). Par contre, on peut remarque que le \"l2 costs\" produit des résultats plus précis puisque tous les mots qui sont regroupés dans le même topic sont plus représentatives et ont plus de sens par rapport à celle trouvé par le kullback-leibler cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 0.310s.\n",
      "Fitting the NMF model (frobenius norm) with TermFrequencyVectorizer features, n_samples=2000 and n_features=1000...\n",
      "done in 0.217s.\n",
      "\n",
      "Topics in NMF model (frobenius norm):\n",
      "nombre d'itération pour la convergence :  128\n",
      "error :  42.1386080329  \n",
      "\n",
      "Topic #0: just people don think like know time good make way really say right ve want did ll new use years\n",
      "Topic #1: windows use dos using window program os drivers application help software pc running ms screen files version card code work\n",
      "Topic #2: god jesus bible faith christian christ christians does heaven sin believe lord life church mary atheism belief human love religion\n",
      "Topic #3: thanks know does mail advance hi info interested email anybody looking card help like appreciated information send list video need\n",
      "Topic #4: car cars tires miles 00 new engine insurance price condition oil power speed good 000 brake year models used bought\n",
      "Topic #5: edu soon com send university internet mit ftp mail cc pub article information hope program mac email home contact blood\n",
      "Topic #6: file problem files format win sound ftp pub read save site help image available create copy running memory self version\n",
      "Topic #7: game team games year win play season players nhl runs goal hockey toronto division flyers player defense leafs bad teams\n",
      "Topic #8: drive drives hard disk floppy software card mac computer power scsi controller apple mb 00 pc rom sale problem internal\n",
      "Topic #9: key chip clipper keys encryption government public use secure enforcement phone nsa communications law encrypted security clinton used legal standard\n",
      "\n",
      "#########################################################################\n",
      "Loading dataset...\n",
      "done in 0.396s.\n",
      "Fitting the NMF model (frobenius norm) with CountVectorizer features, n_samples=2000 and n_features=1000...\n",
      "done in 0.245s.\n",
      "\n",
      "Topics in NMF model (frobenius norm):\n",
      "nombre d'itération pour la convergence :  133\n",
      "error :  42.1386079206  \n",
      "\n",
      "Topic #0: just people don think like know time good make way really say right ve want did ll new use years\n",
      "Topic #1: windows use dos using window program os drivers application help software pc running ms screen files version card code work\n",
      "Topic #2: god jesus bible faith christian christ christians does heaven sin believe lord life church mary atheism belief human love religion\n",
      "Topic #3: thanks know does mail advance hi info interested email anybody looking card help like appreciated information send list video need\n",
      "Topic #4: car cars tires miles 00 new engine insurance price condition oil power speed good 000 brake year models used bought\n",
      "Topic #5: edu soon com send university internet mit ftp mail cc pub article information hope program mac email home contact blood\n",
      "Topic #6: file problem files format win sound ftp pub read save site help image available create copy running memory self version\n",
      "Topic #7: game team games year win play season players nhl runs goal hockey toronto division flyers player defense leafs bad teams\n",
      "Topic #8: drive drives hard disk floppy software card mac computer power scsi controller apple mb 00 pc rom sale problem internal\n",
      "Topic #9: key chip clipper keys encryption government public use secure enforcement phone nsa communications law encrypted security clinton used legal standard\n",
      "\n",
      "#########################################################################\n"
     ]
    }
   ],
   "source": [
    "vectname=['TermFrequencyVectorizer','CountVectorizer']\n",
    "for i in vectname:\n",
    "    runs(_random_state=k,_vectorizerName=i)\n",
    "    k=k+20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Interprétation : ** \n",
    "\n",
    "Bien que le modèle utilisant la représentation term-frequency soit plus rapide avec un nombre d'itérations plus faible que le modèle utilisant le TF-IDF, il a une erreur plus importante.\n",
    "    \n",
    "Ceci pourrait etre dû au fait que les méthodes TF-IDF ont de nombreux avantages par rapport à la représentation TF:\n",
    "\n",
    "La fréquence-terme (TF) n'est qu'une partie de l'approche TF-IDF pour la recherche d'information. L'autre partie est la fréquence de document inverse (IDF) qui est une mesure de la rareté d'un terme.\n",
    "\n",
    "Il fournit une métrique de base pour extraire les termes les plus descriptifs d'un document et nous pouvons donc facilement calculer la similarité entre deux documents qui l'utilisent.\n",
    "\n",
    "Il est facile de remarquer que les résultats avec TF-IDF sont plus appropriés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Partie 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def puissance(w,h,k):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    w: matrice\n",
    "    h: matrice\n",
    "    k: ordre de la puissance\n",
    "    \n",
    "    \n",
    "    \n",
    "    output:\n",
    "    x: (w*h)**k\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    x=np.dot(w,h)\n",
    "    if((k)==-1):\n",
    "        x=np.divide(np.ones(x.shape),x)\n",
    "    else:\n",
    "        x=np.power(x,k)\n",
    "    return x\n",
    "\n",
    "def beta_divergence(V,W,H,beta,F,N,K):\n",
    "\n",
    "    div = 0\n",
    "    WH = np.dot(W, H)\n",
    "    for i in range(F):\n",
    "        for j in range(N):\n",
    "                x = V[i][j] if V[i][j] != 0 else np.finfo(np.double).tiny\n",
    "                y = WH[i][j]\n",
    "                if beta == 1: \n",
    "                    div += x*np.log(x/y) - x + y\n",
    "                elif beta == 0: \n",
    "                    div += (x/y) * np.log(x/y) - 1\n",
    "                else: \n",
    "                    div += 1/(beta*(beta-1))*(pow(x,beta) + (beta-1)*pow(y,beta) - beta*x*pow(y,beta-1))\n",
    "    return div\n",
    "    \n",
    "def NMF_function(V,W=None,H=None,beta=1,nbr_iter=20):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    V:\n",
    "    W: matrice W initiale(peut être non définie)\n",
    "    H: matrice W initiale(peut être non définie)\n",
    "    beta: coefficient de la beta divergence\n",
    "    nbr_iter: nombre d'iteration\n",
    "    \n",
    "    \n",
    "    \n",
    "    output:\n",
    "    W: matrice W predite\n",
    "    H: matrice H predite\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    i=1\n",
    "    eps=1\n",
    "    F = len(V) #Number of V rows\n",
    "    N = len(V[0]) #Number of V columns\n",
    "\n",
    "    if W is None:\n",
    "        W = np.random.rand(F,10)\n",
    "        \n",
    "    if H is None:\n",
    "        H = np.random.rand(10,N)\n",
    "    diff=1\n",
    "    \n",
    "    while(i<nbr_iter):\n",
    "        A = np.dot(W.T, np.multiply(puissance(W,H,beta-2), V))\n",
    "        B = np.dot(W.T, puissance(W,H,beta-1))\n",
    "        Matrix_div = A / B\n",
    "        H = np.multiply(H, Matrix_div)\n",
    "        \n",
    "        A = np.dot(np.multiply(puissance(W,H,beta-2), V),H.T)\n",
    "        B = np.dot(puissance(W,H,beta-1), H.T)\n",
    "        Matrix_div = A / B\n",
    "        W = np.multiply(W, Matrix_div)\n",
    "        \n",
    "        matrix=np.dot(W,H)\n",
    "        diff=np.linalg.norm(V-matrix)\n",
    "        init_error = beta_divergence(V,W,H,beta,F,N,10)\n",
    "        print('l\\'erreur à l\\'intération ',i,'est :',init_error)\n",
    "        i+=1\n",
    "    \n",
    "    return W,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 0.387s.\n",
      "l'erreur à l'intération  1 est : 198383.022059\n",
      "l'erreur à l'intération  2 est : 197721.250885\n",
      "l'erreur à l'intération  3 est : 197162.163781\n",
      "l'erreur à l'intération  4 est : 196683.606322\n",
      "l'erreur à l'intération  5 est : 196269.382964\n",
      "l'erreur à l'intération  6 est : 195907.339275\n",
      "l'erreur à l'intération  7 est : 195588.179304\n",
      "l'erreur à l'intération  8 est : 195304.674164\n",
      "l'erreur à l'intération  9 est : 195051.11917\n",
      "l'erreur à l'intération  10 est : 194822.9532\n",
      "l'erreur à l'intération  11 est : 194616.486524\n",
      "l'erreur à l'intération  12 est : 194428.70274\n",
      "l'erreur à l'intération  13 est : 194257.112318\n",
      "l'erreur à l'intération  14 est : 194099.642751\n",
      "l'erreur à l'intération  15 est : 193954.555067\n",
      "l'erreur à l'intération  16 est : 193820.379611\n",
      "l'erreur à l'intération  17 est : 193695.866106\n",
      "l'erreur à l'intération  18 est : 193579.944429\n",
      "l'erreur à l'intération  19 est : 193471.693499\n",
      "la matrice W est :  [[ 0.64331309  0.84075369  0.31521759 ...,  0.70681393  0.01233081\n",
      "   0.30273314]\n",
      " [ 0.384054    0.70257179  0.70328831 ...,  0.23733966  0.49134548\n",
      "   0.78483561]\n",
      " [ 0.00402399  0.60879295  0.52329004 ...,  0.29641984  0.46472675\n",
      "   0.35173422]\n",
      " ..., \n",
      " [ 0.85507919  0.38290159  0.60803898 ...,  0.68829754  0.54231175\n",
      "   0.70965106]\n",
      " [ 0.50804572  0.5331598   0.44306768 ...,  0.53492324  0.64856626\n",
      "   0.30354861]\n",
      " [ 0.95594588  0.49970426  0.11312057 ...,  0.21105016  1.02585635\n",
      "   0.47019068]]\n",
      "la matrice H est :  [[ 0.01254098  0.09745978  0.18770865 ...,  0.13382569  0.11126525\n",
      "   0.13955867]\n",
      " [ 0.07849575  0.10421945  0.00043098 ...,  0.13401951  0.07476217\n",
      "   0.00252308]\n",
      " [ 0.10571514  0.15348233  0.09900364 ...,  0.1146354   0.06652139\n",
      "   0.1270431 ]\n",
      " ..., \n",
      " [ 0.13907796  0.13450642  0.02705677 ...,  0.13015062  0.14115682\n",
      "   0.09939588]\n",
      " [ 0.1407107   0.01879141  0.19881386 ...,  0.04201276  0.10091654\n",
      "   0.11075964]\n",
      " [ 0.12690156  0.06260076  0.07798311 ...,  0.10348657  0.12713143\n",
      "   0.15905858]]\n"
     ]
    }
   ],
   "source": [
    "features, feature_names = FtoV()\n",
    "\n",
    "V1 = np.random.rand(features.shape[0], features.shape[1])\n",
    "V1 = np.array(V1) # Data matrix F x N \n",
    "F = len(V1) #Number of V rows\n",
    "N = len(V1[0])\n",
    "W = np.random.rand(F,10)\n",
    "H = np.random.rand(10,N)\n",
    "W,H=NMF_function(V1,W,H)\n",
    "print('la matrice W est : ',W)\n",
    "print('la matrice H est : ',H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
